@article{VanDijk,
abstract = {Deep neural networks have lead to a breakthrough in depth estimation from single images. Recent work often focuses on the accuracy of the depth map, where an evaluation on a publicly available test set such as the KITTI vision benchmark is often the main result of the article. While such an evaluation shows how well neural networks can estimate depth, it does not show how they do this. To the best of our knowledge, no work currently exists that analyzes what these networks have learned. In this work we take the MonoDepth network by Godard et al. and investigate what visual cues it exploits for depth estimation. We find that the network ignores the apparent size of known obstacles in favor of their vertical position in the image. Using the vertical position requires the camera pose to be known; however we find that MonoDepth only partially corrects for changes in camera pitch and roll and that these influence the estimated depth towards obstacles. We further show that MonoDepth's use of the vertical image position allows it to estimate the distance towards arbitrary obstacles, even those not appearing in the training set, but that it requires a strong edge at the ground contact point of the object to do so. In future work we will investigate whether these observations also apply to other neural networks for monocular depth estimation.},
archivePrefix = {arXiv},
arxivId = {1905.07005v1},
author = {{Van Dijk}, Tom and {De Croon}, Guido and Nl, G C H E Decroon@tudelft},
eprint = {1905.07005v1},
file = {:C$\backslash$:/Users/Jairo Enrique/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Dijk, De Croon, Nl - Unknown - How do neural networks see depth in single images.pdf:pdf},
title = {{How do neural networks see depth in single images?}}
}
@incollection{Aharchi2020,
abstract = {In recent years, 3D model visualization techniques have made enormous progress. This evolution has not only touched the technical side but also the hardware side. It is no longer necessary to have expensive machines to see a world in 3D; a simple computer can do the trick. Historically, research has fo-cused on the development of 3D information and acquisition techniques from scenes and objects. These acquisition methods require expertise and complex calibration procedures whenever the acquisition system was used. All this creates an important demand for flexibility in these methods of acquisition because of these different factors, many techniques have emerged. Many of them only need a camera and a computer to create a 3D world from a scene.},
author = {Aharchi, M. and {Ait Kbir}, M.},
doi = {10.1007/978-3-030-37629-1_37},
file = {:C$\backslash$:/Users/Jairo Enrique/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aharchi, Ait Kbir - 2020 - A Review on 3D Reconstruction Techniques from 2D Images.pdf:pdf},
pages = {510--522},
title = {{A Review on 3D Reconstruction Techniques from 2D Images}},
year = {2020}
}
@article{Haseeb2018,
abstract = {In this paper, a machine learning setup that provides the obstacle detection system with a method to estimate the distance from the monocular camera to the object viewed with the camera is presented. In particular, the preliminary results of an ongoing research to allow the on-board multisensory system, which is under development within H2020 Shift2Rail project SMART, to autonomously learn distances to objects, possible obstacles on the rail tracks ahead of the locomotive are given. The presented distance estimation system is based on Multi Hidden-Layer Neural Network, named DisNet, which is used to learn and predict the distance between the object and the camera sensor. The DisNet was trained using a supervised learning technique where the input features were manually calculated parameters of the object bounding boxes resulted from the YOLO object classifier and outputs were the accurate 3D laser scanner measurements of the distances to objects in the recorded scene. The presented DisNet-based distance estimation system was evaluated on the images of railway scenes as well as on the images of a road scene. Shown results demonstrate a general nature of the proposed DisNet system that enables its use for the estimation of distances to objects imaged with different types of monocular cameras.},
author = {Haseeb, Muhammad Abdul and Guan, Jianyu and Risti{\'{c}}, Danijela and Gr{\"{a}}ser, Axel},
file = {:C$\backslash$:/Users/Jairo Enrique/Desktop/disnet.pdf:pdf},
journal = {10th Planning, Perception and Navigation for Intelligent Vehicles},
title = {{DisNet : A novel method for distance estimation from monocular camera}},
year = {2018}
}
@misc{Mertan2021,
abstract = {We review solutions to the problem of depth estimation, arguably the most important subtask in scene understanding. We focus on the single image depth estimation problem. Due to its properties, the single image depth estimation problem is currently best tackled with machine learning methods, most successfully with convolutional neural networks. We provide an overview of the field by examining key works. We examine non-deep learning approaches that mostly predate deep learning and utilize hand-crafted features and assumptions, and more recent works that mostly use deep learning techniques. The single image depth estimation problem is tackled in a supervised fashion with absolute or relative depth information acquired from human or sensor-labeled data, or in an unsupervised way using unlabeled stereo images or video datasets. We also study multitask approaches that combine the depth estimation problem with related tasks such as semantic segmentation and surface normal estimation. Finally, we discuss investigations into the mechanisms, principles, and failure cases of contemporary solutions.},
archivePrefix = {arXiv},
arxivId = {2104.06456},
author = {Mertan, Alican and Duff, Damien Jade and Unal, Gozde},
booktitle = {Digital Signal Processing: A Review Journal},
doi = {10.1016/j.dsp.2022.103441},
eprint = {2104.06456},
file = {:C$\backslash$:/Users/Jairo Enrique/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mertan, Duff, Unal - 2021 - Single Image Depth Estimation An Overview.pdf:pdf},
issn = {10512004},
keywords = {Depth from a single image,Review,SIDE,Single image depth estimation,Survey},
month = {apr},
publisher = {Elsevier Inc.},
title = {{Single image depth estimation: An overview}},
url = {http://arxiv.org/abs/2104.06456 http://dx.doi.org/10.1016/j.dsp.2022.103441},
volume = {123},
year = {2022}
}
@inproceedings{Ann2017,
abstract = {In this paper, a 3D scene reconstruction by using stereo vision is presented. Stereo camera parameters from the camera calibration process and disparity map are two important parameters to obtain an accurate result for the 3D reconstruction. 3D reconstruction process generates the coordinates of world points (point cloud). From the information of the point cloud, the interested object is segmented out. Additionally, the noises left in the image is eliminated. The experimental result obtained shows that only the background and the interested object from the overall scene appeared in the processed image. The center of gravity is also determined as the reference value for the robot navigation. An estimation error model is also introduced in this study to increase the accuracy of the distance measurement by using the developed stereo vision system from the mobile robot. This experiment provides a foundation for navigation and object tracking for a mobile robot.},
author = {Ann, Nurnajmin Qasrina and Achmad, M. S.Hendriyawan and Bayuaji, Luhur and Daud, M. Razali and Pebrianti, Dwi},
booktitle = {Proceedings - 2016 IEEE International Conference on Automatic Control and Intelligent Systems, I2CACIS 2016},
doi = {10.1109/I2CACIS.2016.7885292},
file = {:C$\backslash$:/Users/Jairo Enrique/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ann et al. - 2017 - Study on 3D scene reconstruction in robot navigation using stereo vision.pdf:pdf},
isbn = {9781509041862},
keywords = {3D scene reconstruction,robot navigation,stereo camera calibration,stereo vision},
month = {mar},
pages = {72--77},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Study on 3D scene reconstruction in robot navigation using stereo vision}},
year = {2017}
}
